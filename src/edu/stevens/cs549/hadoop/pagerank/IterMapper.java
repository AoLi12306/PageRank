package edu.stevens.cs549.hadoop.pagerank;

import java.io.IOException;

import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.io.*;

public class IterMapper extends Mapper<LongWritable, Text, Text, Text> {

	public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException,
			IllegalArgumentException {
		String line = value.toString(); // Converts Line to a String
		String[] sections = line.split("\t"); // Splits it into two parts. Part 1: node+rank | Part 2: adj list

		if (sections.length > 2) // Checks if the data is in the incorrect format
		{
			throw new IOException("Incorrect data format");
		}
		if (sections.length != 2) {
			return;
		}
		
		System.out.println("IterMapper: section[0] ============ " + sections[0]);
		System.out.println("IterMapper: section[1] ============ " + sections[1]);
		/* 
		 * TODO: finish
		 * emit key: adj vertex, value: computed weight.
		 * 
		 * Remember to also emit the input adjacency list for this node!
		 * Put a marker on the string value to indicate it is an adjacency list.
		 * 
		 */
		
		
		/*
		 * 	input:
		 * 		key: node+rank 
		 * 		value: adj list			exampe: {node1, node2,node3 ...}
		 * 	
		 * 	output:
		 * 		case1:
		 * 		key: nodei
		 * 		value: rank
		 * 
		 * 		case2:
		 * 		key: node
		 * 		value: -adj list		
		 * 	
		 * 		in case2: value     "-" is used to tell reducer that, this is a adj list
		 * 		
		 * 
		 * */
		
		
		
		/*
		 * 				Google 
		 * 					Regex Cheatsheets
		 * 				for the split part
		 * 		
		 * */
		
		
		/*
		 * split("+") would fail because "+" is key word of reg
		 * 
		 * */
		String[] node_and_rank = sections[0].split("\\+");
		
		/*
		 * trim() is needed because the result of initReduce is 
		 * 		node+rank [Tab] adj_list
		 * We need to remove the extra space, generated by [Tab] 
		 * */
		String[] adj_vertexes =  sections[1].trim().split("\\s+");
		
		
		
		
		if( node_and_rank.length == 2 ){
			
			String node = node_and_rank[0];
			String rank = node_and_rank[1];
			
			System.out.println("IterMapper: node ============ " + node_and_rank[0]);
			System.out.println("IterMapper: rank ============ " + node_and_rank[1]);
			
			
			double rank_double = Double.parseDouble(rank);
			
			double weight = PageRankDriver.DECAY * (rank_double / adj_vertexes.length );   //weight = d * (rank/N)
			
			String out_value = String.valueOf(weight);
			
			for(String vertex: adj_vertexes){
				
				System.out.println("IterMapper: vertex ============ " + vertex);
				
				context.write(new Text(vertex), new Text(out_value));
		
			}
			
			/*
			 * 
			 * 
			 * 
			 * */
			context.write(new Text(node), new Text("-"+sections[1]));
		}
		else{
			
			throw new IOException("Incorrect data format£º node+rank");
			
		}

	}

}
